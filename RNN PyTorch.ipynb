{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted Training of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce RTX 3080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:11<00:00, 340.82it/s]\n",
      "100%|██████████| 14952/14952 [00:18<00:00, 793.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.1316, Val Loss: 0.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:11<00:00, 340.37it/s]\n",
      "100%|██████████| 14952/14952 [00:18<00:00, 796.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train Loss: 0.1288, Val Loss: 0.1249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:10<00:00, 343.76it/s]\n",
      "100%|██████████| 14952/14952 [00:18<00:00, 805.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train Loss: 0.1270, Val Loss: 0.1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:09<00:00, 346.54it/s]\n",
      "100%|██████████| 14952/14952 [00:18<00:00, 806.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train Loss: 0.1271, Val Loss: 0.1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:23<00:00, 313.08it/s]\n",
      "100%|██████████| 14952/14952 [00:19<00:00, 769.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train Loss: 0.1273, Val Loss: 0.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:31<00:00, 295.93it/s]\n",
      "100%|██████████| 14952/14952 [00:19<00:00, 753.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train Loss: 0.1249, Val Loss: 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:24<00:00, 309.94it/s]\n",
      "100%|██████████| 14952/14952 [00:18<00:00, 797.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train Loss: 0.1261, Val Loss: 0.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:22<00:00, 315.19it/s]\n",
      "100%|██████████| 14952/14952 [00:19<00:00, 778.39it/s]\n",
      "C:\\Users\\clare\\AppData\\Local\\Temp\\ipykernel_36260\\1181370692.py:178: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_rnn_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Train Loss: 0.1255, Val Loss: 0.1255\n",
      "Early stopping triggered.\n",
      "MODEL TRAINED!!\n",
      "RNN Accuracy: 0.9710\n",
      "RNN F1 Score: 0.0097\n",
      "ROC AUC Score: 0.6756\n",
      "Confusion Matrix:\n",
      " [[1858073     140]\n",
      " [  55307     272]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99   1858213\n",
      "         1.0       0.66      0.00      0.01     55579\n",
      "\n",
      "    accuracy                           0.97   1913792\n",
      "   macro avg       0.82      0.50      0.50   1913792\n",
      "weighted avg       0.96      0.97      0.96   1913792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load and preprocess the data\n",
    "file_path = r\"G:\\My Drive\\Columbia Business School\\Applied Machine Learning\\Combined Code\\Chinese-Stock-Market-Quantitative-Model\\combined_data_with_y_ta.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.sort_values(by=['timestamp', 'ticker'], inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns='y')\n",
    "y = df['y']\n",
    "\n",
    "# Normalize numeric features\n",
    "numeric_columns = X.drop(columns=['timestamp', 'ticker']).columns\n",
    "scaler = StandardScaler()\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "split_date = '2020-01-01'\n",
    "binary_threshold = 0.1\n",
    "y_binary = (y >= binary_threshold).astype(int)\n",
    "\n",
    "train_mask = df['timestamp'] < split_date\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X[train_mask], \n",
    "    y_binary[train_mask], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, \n",
    "    y_train_full, \n",
    "    test_size=0.25, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.drop(columns=['timestamp'])\n",
    "X_val = X_val.drop(columns=['timestamp'])\n",
    "X_test = X_test.drop(columns=['timestamp'])\n",
    "\n",
    "# Define the sliding window function\n",
    "def create_sliding_window(data, labels, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(labels[i + window_size - 1])  # Target is the last value in the window\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Apply sliding window on the training, validation, and test sets\n",
    "window_size = 5\n",
    "X_train_sliding, y_train_sliding = create_sliding_window(X_train.values, y_train.values, window_size)\n",
    "X_val_sliding, y_val_sliding = create_sliding_window(X_val.values, y_val.values, window_size)\n",
    "X_test_sliding, y_test_sliding = create_sliding_window(X_test.values, y_test.values, window_size)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_sliding, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_sliding, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_sliding, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_sliding, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_sliding, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_sliding, dtype=torch.float32)\n",
    "\n",
    "# Create PyTorch datasets and loaders\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TimeSeriesDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TimeSeriesDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "y_train_tensor = (y_train_tensor >= 0.5).float()\n",
    "y_val_tensor = (y_val_tensor >= 0.5).float()\n",
    "y_test_tensor = (y_test_tensor >= 0.5).float()\n",
    "\n",
    "# Define the RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, 64, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(64, 32, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]  # Use the output of the last time step\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "input_size = X_train_sliding.shape[2]\n",
    "model = RNNModel(input_size).to(device)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define optimizer, loss function, and device\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50):\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in tqdm(train_loader):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred.squeeze(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in tqdm(val_loader):\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                loss = criterion(y_pred.squeeze(), y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_rnn_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "print(\"MODEL TRAINED!!\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.load_state_dict(torch.load('best_rnn_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        y_pred_list.append(y_pred.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())\n",
    "\n",
    "y_pred_list = np.concatenate(y_pred_list).squeeze()\n",
    "y_true_list = np.concatenate(y_true_list).squeeze()\n",
    "y_pred_binary = (y_pred_list >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_true_list, y_pred_binary)\n",
    "f1 = f1_score(y_true_list, y_pred_binary)\n",
    "roc_auc = roc_auc_score(y_true_list, y_pred_list)\n",
    "conf_matrix = confusion_matrix(y_true_list, y_pred_binary)\n",
    "\n",
    "print(f\"RNN Accuracy: {accuracy:.4f}\")\n",
    "print(f\"RNN F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_report(y_true_list, y_pred_binary))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Loss training for RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572389"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming y_train_tensor contains binary labels (0 or 1)\n",
    "num_zeros = (y_train_tensor == 0).sum().item()  # Count the number of '0' labels\n",
    "num_ones = (y_train_tensor == 1).sum().item()   # Count the number of '1' labels\n",
    "\n",
    "# Calculate class weight as inverse of class frequency\n",
    "weight_for_class_1 = num_zeros / num_ones  # Higher weight for minority class\n",
    "pos_weight = torch.tensor([weight_for_class_1]).to(device)  # Weight for positive class '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce RTX 3080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:25<00:00, 307.76it/s]\n",
      "100%|██████████| 14952/14952 [00:19<00:00, 749.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 1.3143, Val Loss: 1.2841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:30<00:00, 298.35it/s]\n",
      "100%|██████████| 14952/14952 [00:20<00:00, 726.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train Loss: 1.2640, Val Loss: 1.2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:26<00:00, 306.61it/s]\n",
      "100%|██████████| 14952/14952 [00:20<00:00, 738.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train Loss: 1.2589, Val Loss: 1.2578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:24<00:00, 310.22it/s]\n",
      "100%|██████████| 14952/14952 [00:20<00:00, 734.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train Loss: 1.2629, Val Loss: 1.3173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44855/44855 [02:26<00:00, 305.48it/s]\n",
      "100%|██████████| 14952/14952 [00:20<00:00, 743.18it/s]\n",
      "C:\\Users\\clare\\AppData\\Local\\Temp\\ipykernel_36260\\3351633862.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_rnn_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train Loss: 1.2448, Val Loss: 1.2800\n",
      "Early stopping triggered.\n",
      "MODEL TRAINED!!\n",
      "RNN Accuracy: 0.9079\n",
      "RNN F1 Score: 0.1596\n",
      "ROC AUC Score: 0.6224\n",
      "Confusion Matrix:\n",
      " [[1720838  137375]\n",
      " [  38851   16728]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95   1858213\n",
      "         1.0       0.11      0.30      0.16     55579\n",
      "\n",
      "    accuracy                           0.91   1913792\n",
      "   macro avg       0.54      0.61      0.56   1913792\n",
      "weighted avg       0.95      0.91      0.93   1913792\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load and preprocess the data\n",
    "file_path = r\"G:\\My Drive\\Columbia Business School\\Applied Machine Learning\\Combined Code\\Chinese-Stock-Market-Quantitative-Model\\combined_data_with_y_ta.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.sort_values(by=['timestamp', 'ticker'], inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns='y')\n",
    "y = df['y']\n",
    "\n",
    "# Normalize numeric features\n",
    "numeric_columns = X.drop(columns=['timestamp', 'ticker']).columns\n",
    "scaler = StandardScaler()\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "split_date = '2020-01-01'\n",
    "binary_threshold = 0.1\n",
    "y_binary = (y >= binary_threshold).astype(int)\n",
    "\n",
    "train_mask = df['timestamp'] < split_date\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X[train_mask], \n",
    "    y_binary[train_mask], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, \n",
    "    y_train_full, \n",
    "    test_size=0.25, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.drop(columns=['timestamp'])\n",
    "X_val = X_val.drop(columns=['timestamp'])\n",
    "X_test = X_test.drop(columns=['timestamp'])\n",
    "\n",
    "# Define the sliding window function\n",
    "def create_sliding_window(data, labels, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(labels[i + window_size - 1])  # Target is the last value in the window\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Apply sliding window on the training, validation, and test sets\n",
    "window_size = 5\n",
    "X_train_sliding, y_train_sliding = create_sliding_window(X_train.values, y_train.values, window_size)\n",
    "X_val_sliding, y_val_sliding = create_sliding_window(X_val.values, y_val.values, window_size)\n",
    "X_test_sliding, y_test_sliding = create_sliding_window(X_test.values, y_test.values, window_size)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_sliding, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_sliding, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_sliding, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_sliding, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_sliding, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_sliding, dtype=torch.float32)\n",
    "\n",
    "# Create PyTorch datasets and loaders\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TimeSeriesDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TimeSeriesDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Binarize labels for classification\n",
    "y_train_tensor = (y_train_tensor >= 0.5).float()\n",
    "y_val_tensor = (y_val_tensor >= 0.5).float()\n",
    "y_test_tensor = (y_test_tensor >= 0.5).float()\n",
    "\n",
    "# Calculate class weights\n",
    "num_zeros = (y_train_tensor == 0).sum().item()\n",
    "num_ones = (y_train_tensor == 1).sum().item()\n",
    "weight_for_class_1 = num_zeros / num_ones\n",
    "pos_weight = torch.tensor([weight_for_class_1]).to(device)\n",
    "\n",
    "# Define the RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, 64, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(64, 32, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]  # Use the output of the last time step\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "input_size = X_train_sliding.shape[2]\n",
    "model = RNNModel(input_size).to(device)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define optimizer, loss function, and device\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50):\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in tqdm(train_loader):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred.squeeze(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in tqdm(val_loader):\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                loss = criterion(y_pred.squeeze(), y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_rnn_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "print(\"MODEL TRAINED!!\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.load_state_dict(torch.load('best_rnn_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        y_pred_list.append(y_pred.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())\n",
    "\n",
    "y_pred_list = np.concatenate(y_pred_list).squeeze()\n",
    "y_true_list = np.concatenate(y_true_list).squeeze()\n",
    "y_pred_binary = (y_pred_list >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_true_list, y_pred_binary)\n",
    "f1 = f1_score(y_true_list, y_pred_binary)\n",
    "roc_auc = roc_auc_score(y_true_list, y_pred_list)\n",
    "conf_matrix = confusion_matrix(y_true_list, y_pred_binary)\n",
    "\n",
    "print(f\"RNN Accuracy: {accuracy:.4f}\")\n",
    "print(f\"RNN F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_report(y_true_list, y_pred_binary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
