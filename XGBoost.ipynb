{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eecc7a15-43d6-44a8-9f14-c75e4df7aaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.5482\n",
      "XGBoost F1 Score: 0.0796\n",
      "ROC AUC Score: 0.6380\n",
      "Confusion Matrix:\n",
      " [[1025130  855388]\n",
      " [  20663   37875]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.55      0.70   1880518\n",
      "           1       0.04      0.65      0.08     58538\n",
      "\n",
      "    accuracy                           0.55   1939056\n",
      "   macro avg       0.51      0.60      0.39   1939056\n",
      "weighted avg       0.95      0.55      0.68   1939056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load and sort data\n",
    "df = pd.read_csv('/Users/cyruskurd/Documents/grad_programming/AML/Project work/combined_data_with_y.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp')\n",
    "\n",
    "# Define maxout parameters\n",
    "num_days_maxout = 3\n",
    "threshold = 1.095 ** num_days_maxout\n",
    "\n",
    "# Feature Engineering\n",
    "df['SMA_5'] = df['close'].rolling(window=5).mean()\n",
    "df['SMA_10'] = df['close'].rolling(window=10).mean()\n",
    "df['SMA_20'] = df['close'].rolling(window=20).mean()\n",
    "df['Bollinger_Upper'] = df['SMA_20'] + (df['close'].rolling(window=20).std() * 2)\n",
    "df['Bollinger_Lower'] = df['SMA_20'] - (df['close'].rolling(window=20).std() * 2)\n",
    "df['EMA_10'] = df['close'].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "# RSI Calculation\n",
    "delta = df['close'].diff(1)\n",
    "gain = delta.where(delta > 0, 0)\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "avg_gain = gain.rolling(window=14).mean()\n",
    "avg_loss = loss.rolling(window=14).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# Additional Indicators\n",
    "df['ATR'] = df['close'].rolling(window=14).std()\n",
    "df['Volume_SMA_10'] = df['vol'].rolling(window=10).mean()\n",
    "df['Volume_Spike'] = (df['vol'] > df['Volume_SMA_10']).astype(int)\n",
    "df['Rolling_Std_20'] = df['close'].rolling(window=20).std()\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "X = df[['SMA_5', 'SMA_10', 'SMA_20', 'EMA_10', 'Bollinger_Upper', 'Bollinger_Lower', 'RSI', 'ATR', 'Volume_Spike', 'Rolling_Std_20']]\n",
    "y = df['y']\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test-validation split\n",
    "split_date = '2020-01-01'\n",
    "\n",
    "# Convert y to binary labels based on a threshold\n",
    "binary_threshold = 0.1\n",
    "y_binary = (y >= binary_threshold).astype(int)\n",
    "\n",
    "# Redefine the train-test split with the binary labels\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_scaled[df['timestamp'] < split_date],\n",
    "    y_binary[df['timestamp'] < split_date],\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "# Handle class imbalance using scale_pos_weight\n",
    "negative_counts = (y_train == 0).sum()\n",
    "positive_counts = (y_train == 1).sum()\n",
    "scale_pos_weight = negative_counts / positive_counts\n",
    "\n",
    "# Train XGBoost classifier\n",
    "xgb_model = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42, n_estimators=100,\n",
    "                          max_depth=5, learning_rate=0.1, subsample=0.8)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n",
    "print(f\"XGBoost F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6afbd45e-2a7f-4d87-9269-813a662ee95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.27099323961062"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93e7c9e-f48c-4e5f-9b95-5fa9a43b86f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9698\n",
      "XGBoost F1 Score: 0.0000\n",
      "ROC AUC Score: 0.6373\n",
      "Confusion Matrix:\n",
      " [[1880518       0]\n",
      " [  58538       0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98   1880518\n",
      "           1       0.00      0.00      0.00     58538\n",
      "\n",
      "    accuracy                           0.97   1939056\n",
      "   macro avg       0.48      0.50      0.49   1939056\n",
      "weighted avg       0.94      0.97      0.95   1939056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load and sort data\n",
    "df = pd.read_csv('/Users/cyruskurd/Documents/grad_programming/AML/Project work/combined_data_with_y.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp')\n",
    "\n",
    "# Define maxout parameters\n",
    "num_days_maxout = 3\n",
    "threshold = 1.095 ** num_days_maxout\n",
    "\n",
    "# Feature Engineering\n",
    "df['SMA_5'] = df['close'].rolling(window=5).mean()\n",
    "df['SMA_10'] = df['close'].rolling(window=10).mean()\n",
    "df['SMA_20'] = df['close'].rolling(window=20).mean()\n",
    "df['Bollinger_Upper'] = df['SMA_20'] + (df['close'].rolling(window=20).std() * 2)\n",
    "df['Bollinger_Lower'] = df['SMA_20'] - (df['close'].rolling(window=20).std() * 2)\n",
    "df['EMA_10'] = df['close'].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "# RSI Calculation\n",
    "delta = df['close'].diff(1)\n",
    "gain = delta.where(delta > 0, 0)\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "avg_gain = gain.rolling(window=14).mean()\n",
    "avg_loss = loss.rolling(window=14).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# Additional Indicators\n",
    "df['ATR'] = df['close'].rolling(window=14).std()\n",
    "df['Volume_SMA_10'] = df['vol'].rolling(window=10).mean()\n",
    "df['Volume_Spike'] = (df['vol'] > df['Volume_SMA_10']).astype(int)\n",
    "df['Rolling_Std_20'] = df['close'].rolling(window=20).std()\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "X = df[['SMA_5', 'SMA_10', 'SMA_20', 'EMA_10', 'Bollinger_Upper', 'Bollinger_Lower', 'RSI', 'ATR', 'Volume_Spike', 'Rolling_Std_20']]\n",
    "y = df['y']\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test-validation split\n",
    "split_date = '2020-01-01'\n",
    "\n",
    "# Convert y to binary labels based on a threshold\n",
    "binary_threshold = 0.1\n",
    "y_binary = (y >= binary_threshold).astype(int)\n",
    "\n",
    "# Redefine the train-test split with the binary labels\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_scaled[df['timestamp'] < split_date],\n",
    "    y_binary[df['timestamp'] < split_date],\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "# Handle class imbalance using scale_pos_weight\n",
    "negative_counts = (y_train == 0).sum()\n",
    "positive_counts = (y_train == 1).sum()\n",
    "scale_pos_weight = negative_counts / positive_counts\n",
    "\n",
    "# Train XGBoost classifier\n",
    "xgb_model = XGBClassifier(scale_pos_weight=1, random_state=42, n_estimators=100,\n",
    "                          max_depth=5, learning_rate=0.1, subsample=0.8)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n",
    "print(f\"XGBoost F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ef6ee-3c3c-4d78-a0cb-1b9486b5536c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
